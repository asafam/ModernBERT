{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nlp/achimoa/workspace/ModernHebrewBERT\n",
      "Added /home/nlp/achimoa/workspace/ModernHebrewBERT/src to sys.path\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_dir = '/home/nlp/achimoa/workspace/ModernHebrewBERT'\n",
    "src_dir = os.path.join(project_dir, 'src')\n",
    "\n",
    "os.chdir(project_dir)\n",
    "print(os.getcwd())\n",
    "\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "    print(f\"Added {src_dir} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer name is bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, cast\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from omegaconf import OmegaConf as om\n",
    "\n",
    "config_file = 'yamls/main/mosaic-bert-base-uncased.yaml'\n",
    "with open(\"yamls/defaults.yaml\") as f:\n",
    "        default_cfg = om.load(f)\n",
    "with open(config_file) as f:\n",
    "    yaml_cfg = om.load(f)\n",
    "cfg = om.merge(default_cfg, yaml_cfg)\n",
    "cfg = cast(DictConfig, cfg)  # for type checking\n",
    "\n",
    "print(f\"Tokenizer name is {cfg.get('tokenizer_name', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Iterator, List, Optional, Sequence, Union\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "Tokenizer = Union[PreTrainedTokenizer, PreTrainedTokenizerFast]\n",
    "\n",
    "def build_tokenizer(\n",
    "    om_tokenizer_config: DictConfig,\n",
    ") -> Tokenizer:\n",
    "    os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    resolved_om_tokenizer_config = om.to_container(om_tokenizer_config, resolve=True)\n",
    "    tokenizer_kwargs = resolved_om_tokenizer_config.get(  # type: ignore\n",
    "        \"kwargs\", {}\n",
    "    )\n",
    "    tokenizer_name = resolved_om_tokenizer_config[\"name\"]  # type: ignore\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, **tokenizer_kwargs)\n",
    "\n",
    "    # HuggingFace does not respect the model_max_length kwarg, and overrides it with\n",
    "    # min(kwargs['model_max_length'], original_config['model_max_length']), so we\n",
    "    # explicitly set it here\n",
    "    tokenizer.model_max_length = tokenizer_kwargs.get(\n",
    "        \"model_max_length\",\n",
    "        int(1e30),\n",
    "    )\n",
    "\n",
    "    return tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
